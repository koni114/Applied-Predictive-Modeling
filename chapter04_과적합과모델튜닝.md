# chapter04_과적합과 모델 튜닝
## 4.1 과적합 문제
- 대부분의 모델링 문제에서는 보통 훨씬 고차원 데이터를 다루게 되는데,  
  모델이 훈련 데이터 세트에 얼마나 과적합돼 있는지를 파악하기 위한 방안을 갖추는 것이 매우 중요
- 

## 4.2 모델 튜닝
- 많은 모델에서는 데이터에서 바로 추정이 어려운 매개변수들이 있음  
  --> hyper paramter
- SVM 같은 경우 cost라는 매개변수가 존재하는데, 값이 커지면 모델은 모든 변수에 대해 값을 정확히 매기기 위해 선이 매우 길어짐  
값이 작아지는 경우 모델은 좀 더 무난한 형태가 됨
- KNN 기법 같은 경우 K parameter는 동률이 나올 경우를 생각하여, 홀수만 지정
- 유전 알고리즘이나 simplex search 기법 등을 이용하여 최적의 튜닝 변수도 찾을 수 있음  
  이런 과정을 통해 알고리즘 적으로 최적의 튜닝 파라미터 값을 구할 수 있음

## 4.3 데이터 분할
- 모델의 일반적인 구축 단계는 다음과 같음
  - 예측 데이터 전처리
  - 모델 변수 추정
  - 모델에 사용할 예측 변수 선정
  - 모델 성능 평가
  - 예측 규칙 미세 조정(ROC 곡선 등)

- 모델링 시 가장 먼저 결정해야 할 것은 어떤 샘플을 사용할 지 결정해야함 
### 임의 샘플링
- 데이터를 훈련 세트와 테스트 세트로 나누는 가장 간단한 방법
### 층위 임의 샘플링
- 데이터 분할 결과를 고려해야 할 경우 사용
- 연속형 데이터도 층별 샘플링이 가능함  
  숫자값을 여러 그룹으로 나누고, 이 그룹 내에서 임의 샘플링 진행
### 최대 비유사도 샘플링(maximum dissimilarity sampling)
- 예측 변수값을 기준으로 나눔
- 두 샘플간의 비유사성을 여러 방법으로 구할 수 있는데, 가장 간단한 방법은 두 샘플 예측 변수 간 거리를 구함
- 비유사도를 데이터 분할에 사용하는 경우
  1. 테스트 세트는 1개의 세트(row)로 부터 시작
  2. 초기 샘플과 어디에도 속하지 않은 샘플 간의 비유사도를 계산
  3. 계산된 샘플 중 가장 비유사도가 큰 데이터 샘플을 test Dataset에 포함
  4. 샘플들을 테스트 세트에 더 할당한 후에는 그룹 간의 비 유사성을 구함  
     비유사도의 평균값이나 최솟값을 사용
  5. 원하는 크기의 테스트 데이터 샘플이 나올 때 까지 1~4번을 반복

## 4.4 리샘플링 기법
### K-fold cross validation
- k는 보통 5나 10을 선택하지만 정해진 것은 없음
  - repeated K-fold cross validation
  - LOOCV(leave-one-out cross-validation)
- k겹 교차 검증은 일반적으로 다른 방법에 비해 분산이 크기 때문에 많이 사용되지 않음  
  만약 훈련 데이터셋이 클 경우, 분산과 편향도는 크게 중요하지 않음
- 작은 k값을 사용해 생긴 편향도는 부트스트랩의 편향도와 유사하지만, 분산은 훨씬 큼

### 일반화 교차 검증(Generalized cross-validation

### 반복적 훈련/테스트 세트 분할
- leave-group-out cross-validation 이나 몬테 카를로 교차 검증 등으로 알려져 있음
- 간단하게 데이터를 모델링 및 예측에 사용할 용도로 여러 개로 분할
- 각 train/test 에 들어갈 데이터의 비율은 사용자가 정함. 보통 반복 횟수에 따라 달라짐
-  k-fold와 다른 점은 샘플이 추출된 부분 집합에 여러번 나타날 수 있음
- 보통 반복 횟수가 k-fold cross-validation 보다 큼
- 리샘플링 기법의 편향도는 부분 집합 데이터의 양이 모델링 세트의 양에 근접할수록 줄어듬  
  통상적으로 좋은 비율은 75 ~ 80%임  
  반복 횟수가 클 때는 비율이 더 높아도 괜찮음
- 보다 안정적인 성능 추정값을 얻고 싶다면, 반복 횟수를 보다 크게 잡아(50 ~ 200회)를 추천
- 부분 집합 데이터의 비율이 커질수록 반복 횟수도 증가해야 성능 추정값의 불확실성을 줄일 수 있음

### 부트스트랩(bootstrap)
- 부트스트랩 샘플은 원데이터 샘플의 크기와 동일
- 따라서 어떤 샘플은 부트스트랩 샘플에 여러번 나타나기도 하고, 전혀 나타나지 않을 수 있음
- 선택되지 않은 샘플은 out-of-bag sample이라고 부름
- 부트스트랩 리샘플링을 반복함에 따라 선택된 샘플로 모델이 만들어지고, 범위 외 샘플을 사용해 예측
- 부트스트랩 오차율은 k-fold cross validation에 비해 불확실성이 적게 나타남
- 평균적으로 부트스트랩 샘플 중 63.2%의 데이터가 한 번 이상 나타나므로 , k ~= 2 인 경우의 k-fold cross-validation과 비슷한 편향도를 보임
- 훈련 세트 크기가 작은 경우, 편향이 생길 수 있으며, 훈련 세트 크기가 커질수록 줄어듬
- 편향 현상을 제거하기 위한 방안이 제시됨
  - 632 기법
    - 편향 문제가 단순 부트스트랩 추정과 훈련 데이터 세트를 예측에 재사용해 추정하는 결과를 합쳐  
      성능 추정값을 구하는데서 발생했다고 지적

## 사례 연구: 신용 평가
- 신용 평가 데이터는 좋음(good), 나쁨(bad)으로 신용 평가가 구분돼 붙은 1,000개의 샘플이 있음
- 모델 정확도를 평가할 때, 모델이 선정되려면 최소 기본 정확도가 70% 이상은 되어야 함

## 최종 튜닝 








